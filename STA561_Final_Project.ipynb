{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STA561_Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeePBbmtvsDkcNj0UfGOzU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YiiiGao/STA561_Final_Project/blob/main/STA561_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rDXKe1W5-FU0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score, ndcg_score\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import itertools\n",
        "from xgboost import XGBClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = pd.read_csv('CollegeBasketballPlayers2009-2021.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "a9YFyi_0-T-8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = raw_dataset.loc[raw_dataset['pick'] >= 1]\n",
        "trainset = new_dataset.loc[new_dataset['year'] < 2021]\n",
        "testset = new_dataset.loc[raw_dataset['year'] == 2021]"
      ],
      "metadata": {
        "id": "XfwZ9Lhf-iAP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_basic = ['treb', 'ast', 'stl', 'blk', 'pts', 'yr']\n",
        "features_advanced = ['eFG', 'TS_per', 'FT_per', 'twoP_per', 'TP_per', 'ast/tov', \n",
        "                     'obpm', 'dbpm', 'oreb', 'dreb', 'TO_per', 'ORB_per', 'DRB_per',\n",
        "                     'AST_per', 'blk_per', 'stl_per', 'Min_per']\n",
        "trainset['yr'] = trainset['yr'].rank(method='dense', ascending=True).astype(int)\n",
        "testset['yr'] = testset['yr'].rank(method='dense', ascending=True).astype(int)\n",
        "trainset['ast/tov'] = trainset['ast/tov'].fillna(trainset['ast/tov'].value_counts().index[1])\n",
        "X_train = np.asarray(trainset[features_basic + features_advanced])\n",
        "X_test = np.asarray(testset[features_basic + features_advanced])\n",
        "y_train_pick = np.asarray(trainset.pick)\n",
        "y_train_year = np.asarray(trainset.year)\n",
        "y_test = np.asarray(testset.pick)"
      ],
      "metadata": {
        "id": "U9F9bdGV-4jD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regression"
      ],
      "metadata": {
        "id": "KneMptR_xVAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ball_model = RandomForestRegressor()\n",
        "ball_model.fit(X_train, y_train_pick)\n",
        "\n",
        "y_pred = ball_model.predict(X_test)\n",
        "y_pred = y_pred.argsort().argsort()\n",
        "y_test = y_test.argsort().argsort()\n",
        "print(y_pred)\n",
        "print(y_test)\n",
        "mae = mean_absolute_error(y_pred, y_test)\n",
        "print(\"MAE: {:,.5f}\".format(mae))"
      ],
      "metadata": {
        "id": "Xaq4BCk0-KzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9140cb72-f410-4f44-9e58-e195e1b1043e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[43 41 12 45 17 23 47 40 11 31 33 34 15 46 10 44 16 32  8 19 27 26 48 30\n",
            " 18 20 39 36 28 25 22  1  6 37  9  4 38  3  0  2 24 13 29  5  7 14 42 21\n",
            " 35]\n",
            "[34 44 11 47  5 42 27 40 19 12 26 48 43 37 32 36 30 45 33 31  7  4 38 20\n",
            "  9 13 46 24 28 25 14  0  2  8 18 39  6  3  1 10 29 15 22 21 23 17 35 16\n",
            " 41]\n",
            "MAE: 10.93878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranking"
      ],
      "metadata": {
        "id": "idJRqoeHFVY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.c_[y_train_pick, y_train_year]"
      ],
      "metadata": {
        "id": "VL_NSmeCGgRG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_pairwise(X, y):\n",
        "    X_new = []\n",
        "    y_new = []\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 1:\n",
        "        y = np.c_[y, np.ones(y.shape[0])]\n",
        "    perm = itertools.permutations(range(X.shape[0]), 2)\n",
        "    for k, (i, j) in enumerate(perm):\n",
        "        if y[i][0] == y[j][0] or y[i][1] != y[j][1]:\n",
        "            continue\n",
        "        X_new.append(np.concatenate((X[i], X[j]), axis=None))\n",
        "        y_new.append(np.sign(y[i][0] - y[j][0]))\n",
        "    return np.asarray(X_new), np.asarray(y_new).ravel()"
      ],
      "metadata": {
        "id": "k1l6piqWEQwT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_ndcg(y_pred, y_test):\n",
        "    scores = np.zeros(y_test.shape)\n",
        "    for i in range(len(scores)):\n",
        "        scores[i] = np.sum(y_pred[i * y_test.shape[0]: (i + 1) * y_test.shape[0]])\n",
        "    rank_pred = scores.argsort().argsort()\n",
        "    return rank_pred, ndcg_score([y_test.argsort().argsort()], [rank_pred])"
      ],
      "metadata": {
        "id": "8VjgaqTR289V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new, y_new = transform_pairwise(X_train, y_train)\n",
        "X_test_new, y_test_new = transform_pairwise(X_test, y_test)\n",
        "rank_model = XGBClassifier()\n",
        "rank_model.fit(X_new, y_new)\n",
        "y_pred = rank_model.predict(X_test_new)\n",
        "print(y_pred)\n",
        "rank_pred, score = calc_ndcg(y_pred, y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "QgpW9V6Ml4hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058fcaef-02ee-4b55-9fd8-e4bac3fe4355"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.  1. -1. ...  1. -1. -1.]\n",
            "0.9285381718884151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Network"
      ],
      "metadata": {
        "id": "Vaf5lR8Z4rbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "NRfjBPlU_ImZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model architecture \n",
        "class BinaryClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassification, self).__init__()\n",
        "        # Number of input features is 48.\n",
        "        self.layer_1 = nn.Linear(46, 128) \n",
        "        self.layer_2 = nn.Linear(128, 128)\n",
        "        self.layer_out = nn.Linear(128, 1) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = self.relu(self.layer_1(inputs))\n",
        "        #x = self.dropout(x)\n",
        "        x = self.relu(self.layer_2(x))\n",
        "        x = self.dropout(x)\n",
        "        #x = self.dropout(x)\n",
        "        x = self.layer_out(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BinaryClassification()\n",
        "model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "iVMl0M8P4q7m"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_new, y_new, train_size=0.2)\n",
        "class TrainData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "train_data = TrainData(torch.FloatTensor(X_train_nn), \n",
        "                       torch.FloatTensor(np.where(y_train_nn == -1, 0, y_train_nn)))\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "class ValidationData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "val_data = ValidationData(torch.FloatTensor(X_test_nn))\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=1)\n",
        "\n",
        "class TestData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "    \n",
        "\n",
        "test_data = TestData(torch.FloatTensor(X_test_new))\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=1)"
      ],
      "metadata": {
        "id": "Q5cWo6JDD6r8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_train_acc(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "metadata": {
        "id": "bDcfQsqsGo-4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_val_acc(model, dataloader):\n",
        "    y_pred_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X_batch in dataloader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_test_pred = model(X_batch)\n",
        "            y_test_pred = torch.sigmoid(y_test_pred)\n",
        "            y_pred_tag = torch.round(y_test_pred)\n",
        "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
        "\n",
        "    y_pred_list = np.array([int(a.squeeze().tolist()) for a in y_pred_list])\n",
        "    acc = accuracy_score(np.where(y_test_nn == -1, 0, y_test_nn), y_pred_list)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "Oombl-hfOMWT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "best_accuracy = 0\n",
        "train_accuracy_list = []\n",
        "val_accuracy_list = []\n",
        "epochs = 100\n",
        "for e in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "        acc = calc_train_acc(y_pred, y_batch.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    if e % 10 == 0:\n",
        "        val_accuracy = calc_val_acc(model, val_loader)\n",
        "        val_accuracy_list.append(val_accuracy)\n",
        "        train_accuracy_list.append(epoch_acc/len(train_loader))\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), 'rank.pt') # save best model\n",
        "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | train acc: {epoch_acc/len(train_loader):.3f} | val acc: {val_accuracy:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UckMus7EnSe",
        "outputId": "13633f02-5dda-4aa6-82da-6764d9c5bbdb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 000: | Loss: 0.70153 | train acc: 58.430 | val acc: 0.648\n",
            "Epoch 010: | Loss: 0.61972 | train acc: 65.554 | val acc: 0.665\n",
            "Epoch 020: | Loss: 0.61727 | train acc: 65.452 | val acc: 0.663\n",
            "Epoch 030: | Loss: 0.61609 | train acc: 65.784 | val acc: 0.645\n",
            "Epoch 040: | Loss: 0.61071 | train acc: 66.202 | val acc: 0.655\n",
            "Epoch 050: | Loss: 0.61535 | train acc: 66.024 | val acc: 0.667\n",
            "Epoch 060: | Loss: 0.61061 | train acc: 66.196 | val acc: 0.630\n",
            "Epoch 070: | Loss: 0.61014 | train acc: 66.326 | val acc: 0.651\n",
            "Epoch 080: | Loss: 0.61965 | train acc: 65.172 | val acc: 0.664\n",
            "Epoch 090: | Loss: 0.61199 | train acc: 66.120 | val acc: 0.665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_state_dict = torch.load('rank.pt')\n",
        "model.load_state_dict(best_state_dict) \n",
        "y_pred = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_test_pred = model(X_batch)\n",
        "        y_test_pred = torch.sigmoid(y_test_pred)\n",
        "        y_pred_tag = torch.round(y_test_pred)\n",
        "        y_pred.append(y_pred_tag.cpu().numpy())\n",
        "\n",
        "y_pred = np.array([int(i.squeeze().tolist()) for i in y_pred])\n",
        "print(y_test_new)\n",
        "print(y_pred)\n",
        "print('Pairwise accuracy: ', accuracy_score(y_test_new, np.where(y_pred == 0, -1, y_pred)))\n",
        "rank, score = calc_ndcg(np.where(y_pred == 0, -1, y_pred), y_test)\n",
        "print(\"NDCG score: \", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwarfpzMWBvv",
        "outputId": "e6cb4510-3ef2-4fa9-aab3-b23915112d0f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.  1. -1. ...  1.  1.  1.]\n",
            "[0 1 0 ... 1 1 0]\n",
            "Pairwise accuracy:  0.6207482993197279\n",
            "NDCG score:  0.8964692007356542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data={'Name': testset['player_name'].values,\n",
        "                        'Rank': np.array([item + 1 for item in rank_pred])})\n",
        "df.to_csv('Rank.csv')"
      ],
      "metadata": {
        "id": "y-m3VF1Y7c2I"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}